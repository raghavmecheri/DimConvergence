{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "from framework.losses import interpoint_distance\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"./results/exp1\"\n",
    "N_RESULT_FILES = 10\n",
    "\n",
    "def _load(name):\n",
    "    with open(name, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "K_VALUES = [5, 10, 20, 30, 40, 50, 60]\n",
    "EPSILON_VALUES = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg_data(RESULTS_DIR, N_RESULT_FILES):\n",
    "    print(\"Listing all result files...\")\n",
    "    for filename in os.listdir(RESULTS_DIR):\n",
    "        print(filename)\n",
    "    \n",
    "    if len(os.listdir(RESULTS_DIR)) != N_RESULT_FILES:\n",
    "        print(\"Some runs are missing please check the results folder\")\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Combining files now....\")\n",
    "    exp2_runs = {}\n",
    "    i=0\n",
    "    print(\"Loading Data...\")\n",
    "    for run in os.listdir(RESULTS_DIR):\n",
    "        result = _load(os.path.join(RESULTS_DIR, run))\n",
    "        result = pd.DataFrame(result)\n",
    "        result = result.drop(['emb_x', 'labels'], axis=1)\n",
    "        \n",
    "        exp2_runs[i] = result\n",
    "        i +=1\n",
    "        \n",
    "    # ---------------------------------------------------------------------------------------- \n",
    "    \n",
    "    # Scatter Table\n",
    "    avg_scatter = exp2_runs[0].copy()\n",
    "    avg_scatter = avg_scatter[avg_scatter['convergence'] == 'scatter']\n",
    "    avg_scatter['loss'] = 0\n",
    "    \n",
    "    #Epsilon Precision-Recall Table:\n",
    "    avg_epsilon_pr = exp2_runs[0].copy()\n",
    "    avg_epsilon_pr = avg_epsilon_pr[avg_epsilon_pr['convergence'] == 'epsilon_precision_recall']\n",
    "    for entry in range(len(avg_epsilon_pr)):\n",
    "        for j in range(len(EPSILON_VALUES)):\n",
    "            avg_epsilon_pr['loss'].iloc[entry][0][j] = 0\n",
    "            avg_epsilon_pr['loss'].iloc[entry][1][j] = 0\n",
    "            \n",
    "    #NN and FN Precision Table\n",
    "    avg_nn_pr = exp2_runs[0].copy()\n",
    "    avg_nn_pr = avg_nn_pr[avg_nn_pr['convergence'] == 'nn_precision']\n",
    "    avg_fn_pr = exp2_runs[0].copy()\n",
    "    avg_fn_pr = avg_fn_pr[avg_fn_pr['convergence'] == 'fn_precision']\n",
    "    \n",
    "    for entry in range(len(avg_nn_pr)):\n",
    "        for j in range(len(K_VALUES)):\n",
    "            avg_nn_pr['loss'].iloc[entry][j] = 0\n",
    "            avg_fn_pr['loss'].iloc[entry][j] = 0\n",
    "    \n",
    "    \n",
    "    # Summing up\n",
    "    for ind in range(N_RESULT_FILES):\n",
    "        df = exp2_runs[ind]\n",
    "        \n",
    "        # Combine Scatter:\n",
    "        avg_scatter['loss'] += df[df['convergence'] == 'scatter']['loss']\n",
    "        \n",
    "        # Combine Epsilon Precision Recall:\n",
    "        df_ep = df[df['convergence'] == 'epsilon_precision_recall']\n",
    "        \n",
    "        for entry in range(len(avg_epsilon_pr)):\n",
    "            for j in range(len(EPSILON_VALUES)):\n",
    "                avg_epsilon_pr['loss'].iloc[entry][0][j] += df_ep['loss'].iloc[entry][0][j]\n",
    "                avg_epsilon_pr['loss'].iloc[entry][1][j] += df_ep['loss'].iloc[entry][1][j]\n",
    "                \n",
    "        # Combine NN and FN Precision:\n",
    "        df_nn = df[df['convergence'] == 'nn_precision']\n",
    "        df_fn = df[df['convergence'] == 'fn_precision']\n",
    "        \n",
    "        for entry in range(len(avg_nn_pr)):\n",
    "            for j in range(len(K_VALUES)):\n",
    "                avg_nn_pr['loss'].iloc[entry][j] += df_nn['loss'].iloc[entry][j]\n",
    "                avg_fn_pr['loss'].iloc[entry][j] += df_fn['loss'].iloc[entry][j]\n",
    "    \n",
    "    #Scaling down to get average:\n",
    "    avg_scatter['loss'] = avg_scatter['loss'] / N_RESULT_FILES\n",
    "    \n",
    "    for entry in range(len(avg_epsilon_pr)):\n",
    "        for j in range(len(EPSILON_VALUES)):\n",
    "            avg_epsilon_pr['loss'].iloc[entry][0][j] = avg_epsilon_pr['loss'].iloc[entry][0][j]/N_RESULT_FILES\n",
    "            avg_epsilon_pr['loss'].iloc[entry][1][j] = avg_epsilon_pr['loss'].iloc[entry][1][j]/N_RESULT_FILES\n",
    "            \n",
    "    for entry in range(len(avg_nn_pr)):\n",
    "            for j in range(len(K_VALUES)):\n",
    "                avg_nn_pr['loss'].iloc[entry][j] = avg_nn_pr['loss'].iloc[entry][j]/N_RESULT_FILES\n",
    "                avg_fn_pr['loss'].iloc[entry][j] = avg_fn_pr['loss'].iloc[entry][j]/N_RESULT_FILES\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    return avg_scatter, avg_epsilon_pr, avg_nn_pr, avg_fn_pr\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing all result files...\n",
      "experimentone_9.pkl\n",
      "experimentone_8.pkl\n",
      "experimentone_10.pkl\n",
      "experimentone_5.pkl\n",
      "experimentone_4.pkl\n",
      "experimentone_6.pkl\n",
      "experimentone_7.pkl\n",
      "experimentone_3.pkl\n",
      "experimentone_2.pkl\n",
      "experimentone_1.pkl\n",
      "---------------------------------------------------------\n",
      "Combining files now....\n",
      "Loading Data...\n"
     ]
    }
   ],
   "source": [
    "t,s,u,v = create_avg_data(RESULTS_DIR, N_RESULT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv('exp1_scatter.csv')\n",
    "s.to_csv('exp1_epsilon_pr.csv')\n",
    "u.to_csv('exp1_nn_pr.csv')\n",
    "v.to_csv('exp1_fn_pr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>sampling</th>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>loss</th>\n",
       "      <th>convergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>random</td>\n",
       "      <td>mnist</td>\n",
       "      <td>umap</td>\n",
       "      <td>([0.8907001559267632, 0.8395912859999799, 0.67...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>random</td>\n",
       "      <td>mnist</td>\n",
       "      <td>tsne</td>\n",
       "      <td>([0.89329308380461, 0.852466086788907, 0.69762...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.3</td>\n",
       "      <td>random</td>\n",
       "      <td>olivetti</td>\n",
       "      <td>umap</td>\n",
       "      <td>([0.8924999999999974, 0.8924999999999974, 0.89...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.3</td>\n",
       "      <td>random</td>\n",
       "      <td>olivetti</td>\n",
       "      <td>tsne</td>\n",
       "      <td>([0.8924999999999974, 0.8924999999999974, 0.89...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.3</td>\n",
       "      <td>stratified</td>\n",
       "      <td>mnist</td>\n",
       "      <td>umap</td>\n",
       "      <td>([0.8894795901156856, 0.8344085281270537, 0.66...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1.0</td>\n",
       "      <td>random</td>\n",
       "      <td>olivetti</td>\n",
       "      <td>tsne</td>\n",
       "      <td>([0.8977500000000018, 0.8977500000000018, 0.89...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1.0</td>\n",
       "      <td>stratified</td>\n",
       "      <td>mnist</td>\n",
       "      <td>umap</td>\n",
       "      <td>([0.8751954425990973, 0.7710669702704275, 0.53...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.0</td>\n",
       "      <td>stratified</td>\n",
       "      <td>mnist</td>\n",
       "      <td>tsne</td>\n",
       "      <td>([0.8751954425990973, 0.7710669702704275, 0.53...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1.0</td>\n",
       "      <td>stratified</td>\n",
       "      <td>olivetti</td>\n",
       "      <td>umap</td>\n",
       "      <td>([0.8977500000000018, 0.8977500000000018, 0.89...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.0</td>\n",
       "      <td>stratified</td>\n",
       "      <td>olivetti</td>\n",
       "      <td>tsne</td>\n",
       "      <td>([0.8977500000000018, 0.8977500000000018, 0.89...</td>\n",
       "      <td>epsilon_precision_recall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size    sampling   dataset algorithm  \\\n",
       "3     0.3      random     mnist      umap   \n",
       "7     0.3      random     mnist      tsne   \n",
       "11    0.3      random  olivetti      umap   \n",
       "15    0.3      random  olivetti      tsne   \n",
       "19    0.3  stratified     mnist      umap   \n",
       "..    ...         ...       ...       ...   \n",
       "239   1.0      random  olivetti      tsne   \n",
       "243   1.0  stratified     mnist      umap   \n",
       "247   1.0  stratified     mnist      tsne   \n",
       "251   1.0  stratified  olivetti      umap   \n",
       "255   1.0  stratified  olivetti      tsne   \n",
       "\n",
       "                                                  loss  \\\n",
       "3    ([0.8907001559267632, 0.8395912859999799, 0.67...   \n",
       "7    ([0.89329308380461, 0.852466086788907, 0.69762...   \n",
       "11   ([0.8924999999999974, 0.8924999999999974, 0.89...   \n",
       "15   ([0.8924999999999974, 0.8924999999999974, 0.89...   \n",
       "19   ([0.8894795901156856, 0.8344085281270537, 0.66...   \n",
       "..                                                 ...   \n",
       "239  ([0.8977500000000018, 0.8977500000000018, 0.89...   \n",
       "243  ([0.8751954425990973, 0.7710669702704275, 0.53...   \n",
       "247  ([0.8751954425990973, 0.7710669702704275, 0.53...   \n",
       "251  ([0.8977500000000018, 0.8977500000000018, 0.89...   \n",
       "255  ([0.8977500000000018, 0.8977500000000018, 0.89...   \n",
       "\n",
       "                  convergence  \n",
       "3    epsilon_precision_recall  \n",
       "7    epsilon_precision_recall  \n",
       "11   epsilon_precision_recall  \n",
       "15   epsilon_precision_recall  \n",
       "19   epsilon_precision_recall  \n",
       "..                        ...  \n",
       "239  epsilon_precision_recall  \n",
       "243  epsilon_precision_recall  \n",
       "247  epsilon_precision_recall  \n",
       "251  epsilon_precision_recall  \n",
       "255  epsilon_precision_recall  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import manifold\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import rbf_kernel as rbf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "X_red = manifold.SpectralEmbedding(n_components=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_VALUES = [10, 20, 30, 40, 50, 60]\n",
    "EPSILON_VALUES = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.8]\n",
    "\n",
    "def _get_k_neighborhood(dataset, k, radius=False):\n",
    "    if radius:\n",
    "        neighbours = NearestNeighbors(radius=k, algorithm='ball_tree').fit(dataset)\n",
    "        return neighbours\n",
    "\n",
    "    neighbors = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(dataset)\n",
    "    return neighbors\n",
    "\n",
    "def _get_similarity_matrix(dataset):\n",
    "    gamma = (1/np.var(pairwise_distances(dataset)))*0.1\n",
    "    return rbf(dataset, gamma=gamma)\n",
    "\n",
    "\n",
    "def get_KNN_precision(original, embedded, mode=\"NN\"):\n",
    "    result = []\n",
    "    for k in K_VALUES:\n",
    "        if mode == \"NN\":\n",
    "            orig_neighbors  = _get_k_neighborhood(original, k)\n",
    "            emb_neighbors  = _get_k_neighborhood(embedded, k)\n",
    "\n",
    "\n",
    "            precision = 0\n",
    "            for x,y in zip(original, embedded):\n",
    "\n",
    "                x_neighbors = orig_neighbors.kneighbors(x.reshape(1,-1), return_distance=False)\n",
    "                y_neighbors = emb_neighbors.kneighbors(y.reshape(1, -1), return_distance=False)\n",
    "\n",
    "                precision += len(np.intersect1d(x_neighbors, y_neighbors))\n",
    "\n",
    "            precision = precision / (k*len(original))\n",
    "\n",
    "            result.append(precision)\n",
    "\n",
    "        elif mode == \"FN\":\n",
    "            orig_dist = pairwise_distances(original)\n",
    "            emb_dist = pairwise_distances(embedded)\n",
    "\n",
    "            precision=0\n",
    "            for ind in range(len(original)):\n",
    "                x_farthest = np.argpartition(orig_dist[ind], -k)[-k:]\n",
    "                y_farthest = np.argpartition(emb_dist[ind], -k)[-k:]\n",
    "\n",
    "                precision += len(np.intersect1d(x_farthest, y_farthest))\n",
    "\n",
    "            precision = precision/ (k*(len(original)))\n",
    "\n",
    "            result.append(precision)\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(str(mode) + \" is an invalid mode. Please select NN or FN\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def _get_epsilon_neighborhood_pr(dataset, embedded, latent=False):\n",
    "    if latent:\n",
    "        print(\"Warning Latent Embedding distances not built. Returning 0\")\n",
    "        return 0\n",
    "\n",
    "    result_precision, result_recall = [], []\n",
    "    print(\"Running Loop over Epsilon\")\n",
    "    for epsilon in EPSILON_VALUES:\n",
    "        dataset_sim = _get_similarity_matrix(dataset)\n",
    "        embedded_sim = _get_similarity_matrix(embedded)\n",
    "\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "\n",
    "        for ind in range(len(embedded)):\n",
    "\n",
    "            d_mask = dataset_sim[ind] > epsilon\n",
    "            emb_mask = embedded_sim[ind] > epsilon\n",
    "            intersection = np.logical_and(d_mask, emb_mask)\n",
    "\n",
    "            intersection_count = np.count_nonzero(intersection)\n",
    "            d_count = np.count_nonzero(d_mask)\n",
    "            emb_count = np.count_nonzero(emb_mask)\n",
    "            \n",
    "\n",
    "            if emb_count:\n",
    "                precision += intersection_count/emb_count\n",
    "            if d_count:\n",
    "                recall += intersection_count/d_count\n",
    "\n",
    "        precision = precision/len(embedded)\n",
    "        recall = recall/len(embedded)\n",
    "\n",
    "        result_precision.append(precision)\n",
    "        result_recall.append(recall)\n",
    "    return result_precision, result_recall\n",
    "\n",
    "def get_original_pr(original, embedded):\n",
    "    return _get_epsilon_neighborhood_pr(original, embedded)\n",
    "\n",
    "def get_latent_pr(latent, embedded):\n",
    "    return _get_epsilon_pr(latent, embedded, latent=True)\n",
    "\n",
    "def interpoint_distance(x1, x2):\n",
    "    net = 0\n",
    "    for a,b in zip(x1, x2):\n",
    "        net += norm(a-b)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiwoon_matrix = euclidean2_np(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_embedded_similarities(embedded):\n",
    "    Y = embedded\n",
    "    (n, d) = Y.shape\n",
    "    print(d)\n",
    "    sum_Y = np.sum(np.square(Y), 1)\n",
    "    num = -2. * np.dot(Y, Y.T)\n",
    "    num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "    num[range(n), range(n)] = 0.\n",
    "    Q = num / np.sum(num)\n",
    "    Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_original_similarities(X):\n",
    "    def Hbeta(D=np.array([]), beta=1.0):\n",
    "        \"\"\"\n",
    "            Compute the perplexity and the P-row for a specific value of the\n",
    "            precision of a Gaussian distribution.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute P-row and corresponding perplexity\n",
    "        P = np.exp(-D.copy() * beta)\n",
    "        sumP = sum(P)\n",
    "        H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "        P = P / sumP\n",
    "        return H, P\n",
    "\n",
    "\n",
    "    def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "        \"\"\"\n",
    "            Performs a binary search to get P-values in such a way that each\n",
    "            conditional Gaussian has the same perplexity.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize some variables\n",
    "        print(\"Computing pairwise distances...\")\n",
    "        (n, d) = X.shape\n",
    "        sum_X = np.sum(np.square(X), 1)\n",
    "        D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "        P = np.zeros((n, n))\n",
    "        beta = np.ones((n, 1))\n",
    "        logU = np.log(perplexity)\n",
    "\n",
    "        # Loop over all datapoints\n",
    "        for i in range(n):\n",
    "\n",
    "            # Print progress\n",
    "            if i % 500 == 0:\n",
    "                print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "            # Compute the Gaussian kernel and entropy for the current precision\n",
    "            betamin = -np.inf\n",
    "            betamax = np.inf\n",
    "            Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "            # Evaluate whether the perplexity is within tolerance\n",
    "            Hdiff = H - logU\n",
    "            tries = 0\n",
    "            while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "                # If not, increase or decrease precision\n",
    "                if Hdiff > 0:\n",
    "                    betamin = beta[i].copy()\n",
    "                    if betamax == np.inf or betamax == -np.inf:\n",
    "                        beta[i] = beta[i] * 2.\n",
    "                    else:\n",
    "                        beta[i] = (beta[i] + betamax) / 2.\n",
    "                else:\n",
    "                    betamax = beta[i].copy()\n",
    "                    if betamin == np.inf or betamin == -np.inf:\n",
    "                        beta[i] = beta[i] / 2.\n",
    "                    else:\n",
    "                        beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "                # Recompute the values\n",
    "                (H, thisP) = Hbeta(Di, beta[i])\n",
    "                Hdiff = H - logU\n",
    "                tries += 1\n",
    "\n",
    "            # Set the final row of P\n",
    "            P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "        # Return final P-matrix\n",
    "        print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "        return P\n",
    "    \n",
    "    def pca(X=np.array([]), no_dims=50):\n",
    "        \"\"\"\n",
    "            Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "            no_dims dimensions.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Preprocessing the data using PCA...\")\n",
    "        (n, d) = X.shape\n",
    "        X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "        (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
    "        Y = np.dot(X, M[:, 0:no_dims])\n",
    "        return Y\n",
    "\n",
    "    X = pca(X).real\n",
    "    (n, d) = X.shape\n",
    "    print(\"Shape is \" + str(n) + \" x \" + str(d))\n",
    "    P = x2p(X, 1e-5)\n",
    "    \n",
    "    P = P + np.transpose(P)\n",
    "    print(\"sum is \" + str(np.sum(P)))\n",
    "    P = P / (2*n)\n",
    "    \n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    return P\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Preprocessing the data using PCA...\n",
      "Shape is 1797 x 50\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 1797...\n",
      "Computing P-values for point 500 of 1797...\n",
      "Computing P-values for point 1000 of 1797...\n",
      "Computing P-values for point 1500 of 1797...\n",
      "Mean value of sigma: 11.630463\n",
      "sum is nan\n"
     ]
    }
   ],
   "source": [
    "t = _get_original_similarities(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.00000000e-12, 1.00000000e-12, 8.38266386e-11, ...,\n",
       "        2.17372644e-12, 2.83097629e-08, 2.69865422e-10],\n",
       "       [1.00000000e-12, 1.00000000e-12, 4.74065879e-08, ...,\n",
       "        1.11982657e-08, 1.48230458e-11, 2.79713310e-11],\n",
       "       [8.38266386e-11, 4.74065879e-08, 1.00000000e-12, ...,\n",
       "        2.00451022e-07, 5.41702556e-10, 1.84201288e-08],\n",
       "       ...,\n",
       "       [2.17372644e-12, 1.11982657e-08, 2.00451022e-07, ...,\n",
       "        1.00000000e-12, 5.54146022e-10, 6.46634738e-06],\n",
       "       [2.83097629e-08, 1.48230458e-11, 5.41702556e-10, ...,\n",
       "        5.54146022e-10, 1.00000000e-12, 3.56913466e-08],\n",
       "       [2.69865422e-10, 2.79713310e-11, 1.84201288e-08, ...,\n",
       "        6.46634738e-06, 3.56913466e-08, 1.00000000e-12]])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances(X):\n",
    "    N = X.shape[0]\n",
    "    ss = np.sum(X**2, axis=1)\n",
    "    dist = np.reshape(ss, [N, 1]) + np.reshape(ss, [1, N]) - 2*np.dot(X, X.T)\n",
    "    dist = dist * np.asarray(dist>0,'float32')\n",
    "    return dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_original_similarities(X, sigma, metric, approxF=0):\n",
    "\n",
    "    N = X.shape[0]\n",
    "    sigma = np.full((1, 1797), sigma)\n",
    "    if metric == 'euclidean':\n",
    "        sqdistance = calculate_distances(X)\n",
    "    elif metric == 'precomputed':\n",
    "        sqdistance = X**2\n",
    "    else:\n",
    "        raise Exception('Invalid metric')\n",
    "    euc_dist     = np.exp(-sqdistance / (np.reshape(2*(sigma**2), [N, 1])))\n",
    "    np.fill_diagonal(euc_dist, 0.0 )\n",
    "\n",
    "    if approxF > 0:\n",
    "        sorted_euc_dist = euc_dist[:,:]\n",
    "        np.sort(sorted_euc_dist, axis=1)\n",
    "        row_sum = np.reshape(np.sum(sorted_euc_dist[:,1:approxF+1], axis=1), [N, 1])\n",
    "    else:\n",
    "        row_sum = np.reshape(np.sum(euc_dist, axis=1), [N, 1])\n",
    "\n",
    "    return euc_dist/row_sum  # Possibly dangerous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_embedded_similarities(Y):\n",
    "    N = Y.shape[0]\n",
    "    sqdistance = calculate_distances(Y)\n",
    "    one_over = 1./(sqdistance + 1)\n",
    "    p_Yp_given_Y =  one_over/one_over.sum(axis=1).reshape((N, 1)) \n",
    "    return p_Yp_given_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPSILON_VALUES = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001]\n",
    "\n",
    "def _get_epsilon_neighborhood_pr(dataset, embedded, latent=False):\n",
    "    if latent:\n",
    "        print(\"Warning Latent Embedding distances not built. Returning 0\")\n",
    "        return 0\n",
    "\n",
    "    result_precision, result_recall = [], []\n",
    "\n",
    "    dataset_sim = _compute_original_similarities(dataset, sigma=11.63, metric=\"euclidean\")\n",
    "    embedded_sim = _compute_embedded_similarities(embedded)\n",
    "\n",
    "    for epsilon in EPSILON_VALUES:\n",
    "\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "\n",
    "        for ind in range(len(embedded)):\n",
    "\n",
    "            d_mask = dataset_sim[ind] > epsilon\n",
    "            emb_mask = embedded_sim[ind] > epsilon\n",
    "            intersection = np.logical_and(d_mask, emb_mask)\n",
    "            print(intersection)\n",
    "            intersection_count = np.count_nonzero(intersection)\n",
    "            d_count = np.count_nonzero(d_mask)\n",
    "            emb_count = np.count_nonzero(emb_mask)\n",
    "\n",
    "            if emb_count:\n",
    "                precision += intersection_count/emb_count\n",
    "            if d_count:\n",
    "                recall += intersection_count/d_count\n",
    "\n",
    "        precision = precision/len(embedded)\n",
    "        recall = recall/len(embedded)\n",
    "\n",
    "        result_precision.append(precision)\n",
    "        result_recall.append(recall)\n",
    "    return result_precision, result_recall\n",
    "\n",
    "def get_original_pr(original, embedded):\n",
    "    return _get_epsilon_neighborhood_pr(original, embedded)\n",
    "\n",
    "def get_latent_pr(latent, embedded):\n",
    "    return _get_epsilon_pr(latent, embedded, latent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_original_pr(X, X_red)"
   ]
  }
 ]
}